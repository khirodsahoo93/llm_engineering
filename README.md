# ğŸš€ LLM Engineering Projects & Portfolio

Welcome to my comprehensive collection of Large Language Model (LLM) engineering projects, machine learning implementations, and data science work. This repository showcases my journey through advanced AI concepts, practical implementations, and performance optimizations.

## ğŸ“‹ Table of Contents

- [ğŸ¯ Overview](#-overview)
- [ğŸ› ï¸ Projects](#ï¸-projects)
- [âš¡ Performance Optimizations](#-performance-optimizations)
- [ğŸ“š Course Materials](#-course-materials)
- [ğŸ”§ Setup & Installation](#-setup--installation)
- [ğŸ“Š Key Achievements](#-key-achievements)
- [ğŸš€ Getting Started](#-getting-started)

## ğŸ¯ Overview

This repository contains my work from the **LLM Engineering Course** and various personal projects focused on:

- **Large Language Model Engineering** - Advanced prompt engineering, fine-tuning, and optimization
- **Python to C++ Optimization** - High-performance code generation and execution
- **Machine Learning Pipeline** - End-to-end ML workflows and model deployment
- **Data Science Projects** - Analytics, visualization, and statistical modeling
- **Interview Preparation** - Technical concepts and coding challenges

## ğŸ› ï¸ Projects

### ğŸ”¥ **Python to C++ Code Optimizer**
- **Location**: `week4/day3.ipynb`
- **Description**: AI-powered system that converts Python code to high-performance C++ implementations
- **Features**:
  - Real-time code generation using GPT-4o and Claude-3.5-Sonnet
  - Interactive Gradio interface with modern UI
  - Performance comparison between Python and C++ versions
  - Automatic compilation and execution
- **Performance**: Achieved **10x speed improvement** over Python implementations

### ğŸ§  **LLM Engineering Course Projects**

#### **Week 1-2: Foundations**
- Local LLM setup with Ollama
- Prompt engineering fundamentals
- Model comparison and evaluation

#### **Week 3: Advanced Models**
- HuggingFace model integration
- Tokenization and embeddings
- Multi-modal AI applications

#### **Week 4: Code Generation & Optimization**
- AI-powered code generation
- Performance benchmarking
- C++ optimization techniques

#### **Week 5: RAG (Retrieval-Augmented Generation)**
- Vector databases and embeddings
- Document processing pipelines
- Knowledge base construction

#### **Week 6: Agent Systems**
- Autonomous AI agents
- Tool integration and function calling
- Multi-step reasoning

#### **Week 7: Fine-tuning & Training**
- Model fine-tuning techniques
- Dataset preparation and augmentation
- Training optimization

#### **Week 8: Production Systems**
- Agent frameworks
- Service deployment
- Monitoring and logging

### ğŸ“Š **Data Science & ML Projects**

#### **Interview Preparation Materials**
- **Location**: `Job applications/Interview preparations/`
- **Content**:
  - Machine Learning concepts and algorithms
  - Python programming challenges
  - Statistics and probability theory
  - Behavioral interview preparation
  - Company-specific interview guides

#### **Performance Optimization**
- **C++ Implementations**: `max_subarray_cpp.cpp`, `optimized.cpp`
- **Algorithms**: Maximum subarray sum, Linear Congruential Generator
- **Benchmarking**: Execution time comparisons and performance metrics

## âš¡ Performance Optimizations

### **C++ vs Python Performance**
- **Maximum Subarray Algorithm**: 10x faster in C++
- **Complex Mathematical Operations**: 5-15x speed improvement
- **Memory Management**: Optimized for M1 Mac architecture

### **Key Optimizations Applied**:
```cpp
// M1 Mac optimized compilation
clang++ -O3 -std=c++17 -march=armv8.3-a -o optimized optimized.cpp

// Performance results
Python: 6.3 seconds
C++: 0.59 seconds (10.7x faster)
```

## ğŸ“š Course Materials

### **LLM Engineering Course Structure**
```
week1/ - Foundations and setup
week2/ - Prompt engineering and evaluation
week3/ - Advanced models and tokenization
week4/ - Code generation and optimization
week5/ - RAG and knowledge bases
week6/ - Agent systems and automation
week7/ - Fine-tuning and training
week8/ - Production deployment
```

### **Community Contributions**
- Enhanced Gradio interfaces
- Additional model integrations
- Performance optimizations
- Documentation improvements

## ğŸ”§ Setup & Installation

### **Prerequisites**
- Python 3.8+
- Anaconda or Miniconda
- Git
- C++ compiler (clang++ for Mac, g++ for Linux)

### **Environment Setup**
```bash
# Clone the repository
git clone https://github.com/khirodsahoo93/llm_engineering.git
cd llm_engineering

# Create conda environment
conda env create -f environment.yml
conda activate llms

# Install additional requirements
pip install -r requirements.txt
```

### **API Keys Setup**
Create a `.env` file with your API keys:
```env
OPENAI_API_KEY=your_openai_key_here
ANTHROPIC_API_KEY=your_anthropic_key_here
```

## ğŸ“Š Key Achievements

### **Technical Skills Demonstrated**
- âœ… **LLM Engineering**: Advanced prompt engineering, fine-tuning, RAG systems
- âœ… **Performance Optimization**: Python to C++ conversion with 10x speed improvements
- âœ… **Machine Learning**: End-to-end ML pipelines, model deployment, evaluation
- âœ… **Software Engineering**: Clean code, documentation, testing, version control
- âœ… **Data Science**: Statistical analysis, visualization, business intelligence

### **Projects Highlights**
- ğŸš€ **AI Code Generator**: Real-time Python to C++ conversion system
- ğŸ§  **RAG System**: Knowledge base construction and retrieval
- ğŸ¤– **Agent Framework**: Autonomous AI agents with tool integration
- ğŸ“Š **Performance Benchmarking**: Comprehensive speed and memory analysis

## ğŸš€ Getting Started

### **Quick Start**
1. **Explore the Course**: Start with `week1/day1.ipynb`
2. **Try the Code Optimizer**: Run `week4/day3.ipynb`
3. **Check Performance**: Compare Python vs C++ implementations
4. **Review Interview Prep**: Browse `Job applications/Interview preparations/`

### **Recommended Learning Path**
1. **Week 1-2**: Foundation concepts and setup
2. **Week 3-4**: Advanced models and optimization
3. **Week 5-6**: RAG and agent systems
4. **Week 7-8**: Production deployment

### **Interactive Features**
- **Gradio Interfaces**: Modern web UIs for AI applications
- **Jupyter Notebooks**: Interactive learning and experimentation
- **Performance Tools**: Real-time benchmarking and comparison

## ğŸ“ Contact & Links

- **GitHub**: [khirodsahoo93](https://github.com/khirodsahoo93)
- **LinkedIn**: [Your LinkedIn Profile]
- **Portfolio**: [Your Portfolio Website]

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ™ Acknowledgments

- **LLM Engineering Course** by Edward Donner
- **Community Contributors** for additional implementations
- **Open Source Libraries** used throughout the projects

---

**â­ Star this repository if you find it helpful!**

*Last updated: January 2025*